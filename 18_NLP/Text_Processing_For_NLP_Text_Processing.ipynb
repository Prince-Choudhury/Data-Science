{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n52McdLcLx4"
      },
      "source": [
        "# Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "diqPBuhhcLx6"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBe1VbsncLx8"
      },
      "source": [
        "# Sample Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8-w0lVJNcLx8"
      },
      "outputs": [],
      "source": [
        "sample_text = \"\"\"\n",
        "Natural language processing (NLP) is a field of artificial intelligence that focuses on the interaction\n",
        "between computers and humans through natural language. The ultimate goal of NLP is to read, decipher,\n",
        "understand, and make sense of human language in a way that is both valuable and meaningful.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6Bf0lpDcLx8"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5E3Oa5echr9",
        "outputId": "28c695c6-5591-49c3-f87a-cc560f6625c7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gELFG6dmcLx9"
      },
      "outputs": [],
      "source": [
        "sentences = sent_tokenize(sample_text)\n",
        "words = [word_tokenize(sentence) for sentence in sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AjwtQnicLx9"
      },
      "source": [
        "# Lowercasing and Removing Special Characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RTLv4UJJcLx9"
      },
      "outputs": [],
      "source": [
        "cleaned_words = [[re.sub(r'[^a-zA-Z0-9]', '', word.lower()) for word in sentence] for sentence in words]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXFE3t39cLx9"
      },
      "source": [
        "# Removing Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "b-U6r_B4cLx9"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [[word for word in sentence if word not in stop_words] for sentence in cleaned_words]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2GVXZUDcLx-"
      },
      "source": [
        "# Stemming and Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HDRlWG7mcLx-"
      },
      "outputs": [],
      "source": [
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "stemmed_words = [[stemmer.stem(word) for word in sentence] for sentence in filtered_words]\n",
        "lemmatized_words = [[lemmatizer.lemmatize(word) for word in sentence] for sentence in filtered_words]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "164QuakWcLx-"
      },
      "source": [
        "# Printing Processed Sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxlOTHJKcLx-",
        "outputId": "cc8dce2a-849a-4c5e-ae4d-5813a1840167"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentences:\n",
            "\n",
            "Natural language processing (NLP) is a field of artificial intelligence that focuses on the interaction\n",
            "between computers and humans through natural language.\n",
            "The ultimate goal of NLP is to read, decipher,\n",
            "understand, and make sense of human language in a way that is both valuable and meaningful.\n",
            "\n",
            "Processed Sentences (Lemmatized):\n",
            "natural language processing  nlp  field artificial intelligence focus interaction computer human natural language \n",
            "ultimate goal nlp read  decipher  understand  make sense human language way valuable meaningful \n"
          ]
        }
      ],
      "source": [
        "print(\"Original Sentences:\")\n",
        "for sentence in sentences:\n",
        "    print(sentence)\n",
        "\n",
        "print(\"\\nProcessed Sentences (Lemmatized):\")\n",
        "for sentence in lemmatized_words:\n",
        "    print(' '.join(sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qCNgLbOcLx_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}